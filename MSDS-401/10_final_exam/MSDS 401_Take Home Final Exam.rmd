---
title: "Take Home Final Exam, Spring 2022"
author: "Chen, Grace"
output: html_document
---

For the take-home part of the MSDS 401 Final Exam, you are tasked with analyzing data on new daily covid-19 cases and deaths in European Union (EU) and European Economic Area (EEA) countries. A data file may be downloaded [here](https://www.ecdc.europa.eu/en/publications-data/data-daily-new-cases-covid-19-eueea-country), *or* you may use the provided **read.csv()** code in the 'setup' code chunk below to read the data directly from the web csv. Either approach is acceptable; the data should be the same.

Once you have defined a data frame with the daily case and death and country data, you are asked to:  (1) perform an Exploratory Data Analysis (EDA), (2) perform some hypothesis testing, (3) perform some correlation testing, and (4) fit and describe a linear regression model. Each of these four (4) items is further explained below and "code chunks" have been created for you in which to add your R code, just as with the R and Data Analysis Assignments. You may add additional code chunks, as needed. You should make comments in the code chunks or add clarifying text between code chunks that you think further your work.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE,
                      message = FALSE)

library(ggplot2)
library(gridExtra)
library(lubridate)
library(tidyverse)
library(dplyr)
library(Hmisc)

# The read.csv() below reads the data directly from the web. You may use this or
# you can download and read from a local copy of the data file. To work from a
# local file, you will need to modify the read.csv() code here:

data <- read.csv("https://opendata.ecdc.europa.eu/covid19/nationalcasedeath_eueea_daily_ei/csv",
                 na.strings = "", fileEncoding = "UTF-8-BOM")

# The zero-th step in any analysis is to 'sanity check' our data. Here, we call
# glimpse() from the 'dplyr' package, but utils::str() would work, as well.
glimpse(data)

# If our read.csv() code above worked as expected, we should have a data frame
# of 8460 rows, 11 columns | variables.

# The last thing we're going to do is drop the 'continentExp' vector (as all
# observations are "Europe"), coerce the 'dateRep' vector to a date format, and
# coerce the country and territory vectors to factors.

data <- data %>%
  select(-c("continentExp")) %>%
  mutate(dateRep = dmy(dateRep),
         countriesAndTerritories = as.factor(countriesAndTerritories),
         geoId = as.factor(geoId),
         countryterritoryCode = as.factor(countryterritoryCode))

```

A data dictionary for the dataset is available [here](https://www.ecdc.europa.eu/sites/default/files/documents/Description-and-disclaimer_daily_reporting.pdf).

#### Definitions:

* "Incidence rate" is equal to new daily cases per 100K individuals. Country population estimates can be found in 'popData2020.' You will calculate a daily incidence rate in item (1), for each country, that we will explore further in items (2) and (3).

* "Fatality rate" is equal to new daily deaths per 100K individuals. Country population estimates can be found in 'popData2020.' You will calculate a daily fatality rate in item (1), for each country, that we will explore further in items (2) and (3).

---

#### 1. Descriptive Statistics
  Perform an Exploratory Data Analysis (EDA). Your EDA is exactly that:  yours. Your knit .html should include the visualizations and summary tables that you find valuable while exploring this dataset. **However**, at minimum, your EDA must include the following:

* Creation of a vector, 'incidence_rate,' equal to the daily new cases per 100K individuals, per country. Country populations are provided in 'popData2020.' This vector should be added to the 'data' data frame.
* Creation of a vector, 'fatality_rate,' equal to the new deaths per 100K individuals, per country. Country populations are provided in 'popData2020.' This vector should be added to the 'data' data frame.
* A visualization exploring new cases or incidence rates, per country, over time. You may choose a subset of countries, if you wish, but your visualization should include at least five (5) countries and include the entire time frame of the dataset.
* A visualization exploring new deaths or fatality rates, per country, over time. You may choose a subset of countries, if you wish, but your visualization should include at least five (5) countries.
* A table or visualization exploring some other aspect of the data. For example, you could explore case fatality rates per country; the number of deaths divided by the total number of cases. Note that to do this, you would want to like across the entire time of the dataset, looking at the total cases and deaths, per country.

```{r descriptive_stats, fig.width = 8, fig.height = 8}
data$incidence_rate <- data$cases * (data$popData2020 / 100000)
data$fatality_rate <- data$deaths * (data$popData2020 / 100000)
data$case_fatality_rate <- data$deaths / data$cases
selectcountries<-subset(data,countriesAndTerritories == c("Germany", "France", "Italy", "Spain", "Poland"))
plot(selectcountries$dateRep, selectcountries$incidence_rate, col = c("red", "blue", "green", "purple", "orange"), xlab="Time", ylab="Incidence Rates", main = "Incidence Rates by Country Over Time", cex = 0.8, pch=19)
legend(x = "topleft", legend = unique(sort(selectcountries$countriesAndTerritories)), col = c("red", "blue", "green", "purple", "orange"), pch=19)
plot(selectcountries$dateRep, selectcountries$fatality_rate, col = c("red", "blue", "green", "purple", "orange"), xlab="Time", ylab="Fatality Rates", main = "Fatality Rates by Country Over Time", cex = 0.8, pch=19)
legend(x = "topleft", legend = unique(sort(selectcountries$countriesAndTerritories)), col = c("red", "blue", "green", "purple", "orange"), pch=19)
plot(selectcountries$dateRep, selectcountries$case_fatality_rate, col = c("red", "blue", "green", "purple", "orange"), xlab="Time", ylab="Case Fatality Rates", main = "Case Fatality Rates by Country Over Time", cex = 0.8, pch=19)
legend(x = "topleft", legend = unique(sort(selectcountries$countriesAndTerritories)), col = c("red", "blue", "green", "purple", "orange"), pch=19)
```

#### 2. Inferential Statistics
  Select two (2) countries of your choosing and compare their incidence or fatality rates using hypothesis testing. At minimum, your work should include the following:

* Visualization(s) comparing the daily incidence or fatality rates of the selected countries,
* A statement of the null hypothesis.
* A short justification of the statistical test selected.
    + Why is the test you selected an appropriate one for the comparison we're making?
* A brief discussion of any distributional assumptions of that test.
    + Does the statistical test we selected require assumptions about our data?
    + If so, does our data satisfy those assumptions?
* Your selected alpha.
* The test function output; i.e. the R output.
* The relevant confidence interval, if not returned by the R test output.
* A concluding statement on the outcome of the statistical test.
    + i.e. Based on our selected alpha, do we reject or fail to reject our null hypothesis?
    
***Answer: The null hypothesis is the population mean for Germany's incidence rate is equal to the population mean for France's incidence rate.The alternate hypothesis is the population mean for Germany's incidence rate is not equal to the population mean for France's incidence rate. I selected to use the T test since the population variance and population mean in this case is unknown. However, distribution assumptions are that the population is normally distributed and that the samples are independent and random. The data is are not paired or dependent on one another. Therefore, our data satisfy those assumptions. I also added to assume that there will be unequal variances between the two countries. My selected alpha for this analysis will be 0.05. Based on the selected alpha of 0.05 and a p value of 0.3635, we fail to reject our null hypothesis. In other words, the population mean for Germany's incidence rate is equal to the population mean for France's incidence rate and there is no significant difference between the incidence rates in Germany and France.  ***

```{r inferential_stats, fig.width = 9, fig.height = 8}
twocountries <- subset(data,countriesAndTerritories == c("Germany", "France"))
plot(twocountries$dateRep, twocountries$incidence_rate, col = c("red", "blue"), xlab="Time", ylab="Incidence Rates", main = "Incidence Rates by Country", cex = 0.8, pch=19)
legend(x = "topleft", legend = unique(sort(twocountries$countriesAndTerritories)), col = c("red", "blue"), pch=19)

France <- subset(twocountries, subset = (countriesAndTerritories == "France"))$incidence_rate
Germany <- subset(twocountries, subset = (countriesAndTerritories == "Germany"))$incidence_rate
t.test(France, Germany, mu=0, alternative ="two.sided", conf.level = 0.95, var.equal = FALSE)
```

#### 3. Correlation
Considering all countries, explore the relationship between incidence rates and fatality rates. At minimum, your work should include the following:

* Visualization(s) showing the distributions of daily incidence and fatality rates, regardless of country. Please note that both country and date should be disregarded here.
* A short statement identifying the most appropriate correlation coefficient.
    + For the correlation we're interested in, which correlation coefficient is most appropriate?
    + Why do you find the correlation coefficient selected to be the most appropriate?
* The calculated correlation coefficient or coefficient test output; e.g. *cor()* or *cor.test()*.

***Answer: The most appropriate correlation coefficient in this scenario would be Kendall's Tau correlation coefficient. The Pearson correlation coefficient requires the data to be normally distributed but from the histograms, both the incidence rate and the fatality rate distributions are skewed right and not normally distributed. ***
  
```{r correlation, fig.width = 8, fig.height = 8}
hist(data$incidence_rate, main='Incidence Rates', col='red', xlab = 'Incidence Rates')
hist(data$fatality_rate, main='Fatality Rates', col='blue', xlab = 'Fatality Rates')
cor.test(data$incidence_rate, data$fatality_rate, method = "kendall")
```

#### 4. Regression
  Here, we will fit a model on data from twenty (20) countries considering total new cases as a function of population, population density and gross domestic product (GDP) per capita. Note that the GDP per capita is given in "purchasing power standard," which considers the costs of goods and services in a country relative to incomes in that country; i.e. we will consider this as appropriately standardized.

Code is given below defining a new data frame, 'model_df,' which provides the total area and standardized GDP per capita for the twenty (20) countries for our model fit. You are responsible for creating a vector of the total new cases across the time frame of the dataset, for each of those countries, and adding that vector to our 'model_df" data frame.

```{r regression_a, fig.width = 8, fig.height = 8}

# The code below creates a new data frame, 'model_df,' that includes the area,
# GDP per capita, population and population density for the twenty (20)
# countries of interest. All you should need to do is execute this code, as is.

# You do not need to add code in this chunk. You will need to add code in the
# 'regression_b,' 'regression_c' and 'regression_d' code chunks.

twenty_countries <- c("Austria", "Belgium", "Bulgaria", "Cyprus", "Denmark",
                      "Finland", "France", "Germany", "Hungary", "Ireland",
                      "Latvia", "Lithuania", "Malta", "Norway", "Poland",
                      "Portugal", "Romania", "Slovakia", "Spain", "Sweden")

sq_km <- c(83858, 30510, 110994, 9251, 44493, 338145, 551695, 357386, 93030,
           70273, 64589, 65300, 316, 385178, 312685, 88416, 238397, 49036,
           498511, 450295)

gdp_pps <- c(128, 118, 51, 91, 129, 111, 104, 123, 71, 190, 69, 81, 100, 142,
             71, 78, 65, 71, 91, 120)

model_df <- data %>%
  select(c(countriesAndTerritories, popData2020)) %>%
  filter(countriesAndTerritories %in% twenty_countries) %>%
  distinct(countriesAndTerritories, .keep_all = TRUE) %>%
  add_column(sq_km, gdp_pps) %>%
  mutate(pop_dens = popData2020 / sq_km) %>%
  rename(country = countriesAndTerritories, pop = popData2020)

```

Next, we need to add one (1) more column to our 'model_df' data frame. Specifically, one that has the total number of new cases for each of the twenty (20) countries. We calculate the total number of new cases by summing all the daily new cases, for each country, across all the days in the dataset.

```{r regression_b}
### The following code will be removed for students to complete the work themselves.

total_cases <- data %>%
  select(c(countriesAndTerritories, cases)) %>%
  group_by(countriesAndTerritories) %>%
  dplyr::summarize(total_cases = sum(cases, na.rm = TRUE)) %>%
  filter(countriesAndTerritories %in% twenty_countries) %>%
  select(total_cases)

model_df <- model_df %>%
  add_column(total_cases)

```

Now, we will fit our model using the data in 'model_df.' We are interested in explaining total cases (response) as a function of population (explanatory), population density (explanatory), and GDP (explanatory).

At minimum, your modeling work should including the following:

* A description - either narrative or using R output - of your 'model_df' data frame.
    + Consider:  what data types are present? What do our rows and columns represent?
* The *lm()* *summary()* output of your fitted model. As we did in the second Data Analysis Assignment, you can pass your fitted model object - i.e. the output of **lm()** - to *summary()* and get additional details, including R^2, on your model fit.
* A short statement on the fit of the model.
    + Which, if any, of our coefficients are statistically significant?
    + What is the R^2 of our model?
    + Should we consider a reduced model; i.e. one with fewer parameters?
    
***Answer: There are all types of data types present in the 'model_df' data frame such as numerical, integer, and factor data types. Our rows represent each of the 20 countries in our analysis. Our columns represent the characteristic of each country including the population, area, GDP per capita, population density, and total number of new cases across all of the times in the 'data' dataset. The population coefficient is statistically significant while the population density and GDP coefficients are not statistically significant. The adjusted R^2 of our model is 0.8878 while the multiple R squared is 0.9055. While there is a slight difference between these numbers, they are are relatively close and it seems like the model is performing well with the fitted data. However, it looks like after removing the population density variable from the model, the adjusted r^2 increase to 0.8942. Therefore, we should consider this reduced model without the population density variable. ***

```{r regression_c}
model <- lm(total_cases ~ pop + pop_dens + gdp_pps, data = model_df)
summary(model)
```

The last thing we will do is use our model to predict the  total new cases of two (2) countries not included in our model fit. At minimum, your work should include:

* The predicted total new cases for both countries.
* The actual total new cases for both countries.
* A short statement on the performance of the model in these two (2) cases.
    + Compare the new predictions to those made on the fitted dataset. You may compare the predicted values or the residuals.
    
***Answer: In both cases with the fitted dataset and the 'newdata' dataset, the prediction values made by the model were off. Based on the original predictions made on the fitted dataset, when the independent variables were very low, in some cases, the model would predict that the total daily cases would be negative which is unreasonable. For instance, Latvia has the lowest GDP and one of the lowest population density and the predicted total cases is -390686. While this was not a problem in the two new countries not included in our model fit, the new predictions made on the total new cases was more inaccurate in those two countries and ended up varying by millions of new cases.***
  
```{r regression_d}

# The code below defines our 'newdata' data frame for applying our model to the
# population, population density and GDP per capita for two (2). Please execute
# the code as given.

country <- c("Luxembourg", "Netherlands")

newdata <- data.frame(country = c("Luxembourg", "Netherlands"),
                      pop = c(626108, 17407585),
                      gdp_pps = c(261, 130),
                      pop_dens = c(626108, 17407585) / c(2586, 41540))

# Add code here returning the actual  total cases from our dataset for the
# Netherlands and Luxembourg.
total_cases <- data %>%
  select(c(countriesAndTerritories, cases)) %>%
  group_by(countriesAndTerritories) %>%
  dplyr::summarize(total_cases = sum(cases, na.rm = TRUE)) %>%
  filter(countriesAndTerritories %in% country) %>%
  select(total_cases)

newdata <- newdata %>%
  add_column(total_cases)

newdata

# Add code here returning the total cases for the Netherlands and Luxembourg
# predicted by our model.

predict(model, newdata=newdata)

```
